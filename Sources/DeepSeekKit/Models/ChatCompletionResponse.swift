import Foundation

/// Response from a chat completion request.
public struct ChatCompletionResponse: Codable, Sendable {
    /// Unique identifier for the completion.
    public let id: String
    
    /// Object type (always "chat.completion").
    public let object: String
    
    /// Unix timestamp of when the completion was created.
    public let created: Int
    
    /// The model used for the completion.
    public let model: String
    
    /// System fingerprint.
    public let systemFingerprint: String?
    
    /// Array of completion choices.
    public let choices: [Choice]
    
    /// Token usage statistics.
    public let usage: Usage
    
    private enum CodingKeys: String, CodingKey {
        case id
        case object
        case created
        case model
        case systemFingerprint = "system_fingerprint"
        case choices
        case usage
    }
}

/// A completion choice.
public struct Choice: Codable, Sendable {
    /// The index of this choice.
    public let index: Int
    
    /// The message generated by the model.
    public let message: ResponseMessage
    
    /// Log probability information.
    public let logprobs: LogProbs?
    
    /// The reason the model stopped generating.
    public let finishReason: FinishReason?
    
    private enum CodingKeys: String, CodingKey {
        case index
        case message
        case logprobs
        case finishReason = "finish_reason"
    }
}

/// Message in a chat completion response.
public struct ResponseMessage: Codable, Sendable {
    /// The role of the message author.
    public let role: MessageRole
    
    /// The content of the message.
    public let content: String?
    
    /// The reasoning content (for reasoner model).
    public let reasoningContent: String?
    
    /// Tool calls made by the assistant.
    public let toolCalls: [ToolCall]?
    
    private enum CodingKeys: String, CodingKey {
        case role
        case content
        case reasoningContent = "reasoning_content"
        case toolCalls = "tool_calls"
    }
}

/// Token usage information.
public struct Usage: Codable, Sendable {
    /// Number of tokens in the prompt.
    public let promptTokens: Int
    
    /// Number of tokens in the completion.
    public let completionTokens: Int
    
    /// Total number of tokens used.
    public let totalTokens: Int
    
    /// Number of prompt tokens that hit the cache.
    public let promptCacheHitTokens: Int?
    
    /// Number of prompt tokens that missed the cache.
    public let promptCacheMissTokens: Int?
    
    private enum CodingKeys: String, CodingKey {
        case promptTokens = "prompt_tokens"
        case completionTokens = "completion_tokens"
        case totalTokens = "total_tokens"
        case promptCacheHitTokens = "prompt_cache_hit_tokens"
        case promptCacheMissTokens = "prompt_cache_miss_tokens"
    }
}

/// Reason why the model stopped generating.
public enum FinishReason: String, Codable, Sendable {
    case stop
    case length
    case toolCalls = "tool_calls"
    case contentFilter = "content_filter"
}

/// Log probability information.
public struct LogProbs: Codable, Sendable {
    /// Log probabilities for each token.
    public let content: [TokenLogProb]?
}

/// Log probability for a single token.
public struct TokenLogProb: Codable, Sendable {
    /// The token.
    public let token: String
    
    /// The log probability.
    public let logprob: Double
    
    /// UTF-8 byte representation.
    public let bytes: [Int]?
    
    /// Top log probabilities.
    public let topLogprobs: [TopLogProb]?
    
    private enum CodingKeys: String, CodingKey {
        case token
        case logprob
        case bytes
        case topLogprobs = "top_logprobs"
    }
}

/// Top log probability entry.
public struct TopLogProb: Codable, Sendable {
    /// The token.
    public let token: String
    
    /// The log probability.
    public let logprob: Double
    
    /// UTF-8 byte representation.
    public let bytes: [Int]?
}